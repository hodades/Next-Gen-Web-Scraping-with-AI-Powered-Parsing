# Next-Gen-Web-Scraping-with-AI-Powered-Parsing

Ce projet automatise lâ€™extraction, la structuration et lâ€™export des fiches produits horlogers depuis [EveryWatch.com](https://everywatch.com), avec un focus sur la marque **Breguet**. Le pipeline utilise Playwright pour simuler une session utilisateur, contourner les blocages, rÃ©cupÃ©rer les donnÃ©es API JSON, puis les transformer en fichiers exploitables (JSON / Excel).

---

## ğŸš€ Objectifs

- Scraper automatiquement des fiches produits horlogers  
- Simuler un vrai navigateur pour Ã©viter les blocages  
- AccÃ©der aux donnÃ©es via des API JSON dynamiques  
- Exporter les rÃ©sultats dans un format structurÃ©  
- Faciliter un futur enrichissement via modÃ¨les IA (GPT)  
- Fournir un export Excel pour visualisation rapide  

---

## ğŸ§  Technologies utilisÃ©es

- Python 3.10+  
- Playwright (contrÃ´le de navigateur avec session persistante)  
- Requests (requÃªtes API avec cookies dynamiques)  
- Pandas (manipulation CSV / JSON)  
- Jupyter Notebook (export vers Excel)  
- OpenAI GPT (prÃ©vu pour parsing intelligent)  

---

## ğŸ“ Structure du projet

```
everywatch-scraper/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Watchfeed.csv               # Liste de liens Ã  scraper
â”‚   â”œâ”€â”€ all_watches_data.json       # RÃ©sultats du scraping
â”‚
â”œâ”€â”€ scraping/
â”‚   â”œâ”€â”€ re_logic_bis2.py            # Scraper principal avec gestion de cookies
â”‚   â””â”€â”€ cookie_login/
â”‚       â”œâ”€â”€ login.py                # Script de login via Playwright (Windows)
â”‚       â”œâ”€â”€ login_mac.py            # Script de login (macOS)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ remplissage_excel.ipynb     # Export JSON â†’ Excel
```

---

## âš™ï¸ Installation

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/ton-compte/everywatch-scraper.git
cd everywatch-scraper
```

### 2. CrÃ©er un environnement virtuel

```bash
python -m venv venv
source venv/bin/activate        # macOS/Linux
venv\Scripts\activate           # Windows
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
playwright install
```

---

## ğŸš€ Lancer le scraping

```bash
python scraping/re_logic_bis2.py
```

Le script lit `Watchfeed.csv`, rafraÃ®chit les cookies toutes les 400 requÃªtes, enregistre les rÃ©sultats dans `all_watches_data.json`, et gÃ¨re les blocages (`403`, erreurs API, etc.).

---

## ğŸ” Connexion manuelle (si nÃ©cessaire)

```bash
python scraping/cookie_login/login.py         # sur Windows
python scraping/cookie_login/login_mac.py     # sur macOS
```

Utilise `page.pause()` pour interagir manuellement ou te connecter si besoin.

---

## ğŸ“¤ Export vers Excel

AprÃ¨s le scraping :

1. Ouvre le fichier `notebooks/remplissage_excel.ipynb`  
2. Lance les cellules pour convertir `all_watches_data.json` en tableau Excel `.xlsx`

---

## âœ… FonctionnalitÃ©s clÃ©s

- Scraping dynamique via Playwright  
- Cookies et sessions utilisateurs gÃ©rÃ©s automatiquement  
- AccÃ¨s Ã  lâ€™API Next.js du site pour donnÃ©es structurÃ©es  
- RÃ©silience aux blocages automatiques  
- Export JSON et Excel exploitables immÃ©diatement  

---

## ğŸ’¡ Applications possibles

- Analyse de marchÃ© horloger  
- Enrichissement de fiches produit e-commerce  
- Pricing algorithmique  
- Veille concurrentielle  
- PrÃ©paration de donnÃ©es pour NLP/IA  


